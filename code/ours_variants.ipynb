{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets_dataloader_pytorch import CustomDataset, load_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, precision_score, average_precision_score\n",
    "\n",
    "from variants import CAMELOT_GMM, class_weight, Camelot_GRU, Camelot_denoising\n",
    "from model_utils import MyLRScheduler, calc_l1_l2_loss\n",
    "from utils import calc_pred_loss, calc_dist_loss, calc_clus_loss, torch_log\n",
    "\n",
    "metrics = ['AUC', 'F1 score', 'Recall', 'NMI']\n",
    "seeds = [1001, 1012, 1134, 2475, 6138, 7415, 1663, 7205, 9253, 1782]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:07<00:00, 1077.80it/s]\n",
      " 50%|█████     | 50/100 [00:13<00:13,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "GMM initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:52<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.77202, \t[0.88815746 0.77457713 0.7570725  0.66826324]\n",
      "F1-score: \t0.31836, \t[0.         0.5        0.77342823 0.        ]\n",
      "Recall: \t0.35247, \t[0.         0.71625767 0.69361702 0.        ]\n",
      "NMI: \t\t0.09827\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:07<00:00, 1062.37it/s]\n",
      " 50%|█████     | 50/100 [00:13<00:13,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "GMM initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:52<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.77126, \t[0.85081673 0.77689006 0.74723754 0.71010611]\n",
      "F1-score: \t0.33555, \t[0.         0.49557522 0.84662577 0.        ]\n",
      "Recall: \t0.34171, \t[0.         0.51533742 0.85148936 0.        ]\n",
      "NMI: \t\t0.10981\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:07<00:00, 1054.09it/s]\n",
      " 50%|█████     | 50/100 [00:13<00:13,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "GMM initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:53<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.78316, \t[0.87332571 0.79366398 0.76300521 0.70263267]\n",
      "F1-score: \t0.34148, \t[0.         0.52094972 0.84497957 0.        ]\n",
      "Recall: \t0.35206, \t[0.         0.57208589 0.83617021 0.        ]\n",
      "NMI: \t\t0.11841\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:06<00:00, 1121.10it/s]\n",
      " 50%|█████     | 50/100 [00:12<00:12,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "GMM initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:12<00:12,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:35<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.76169, \t[0.86565665 0.78824379 0.76648805 0.62636148]\n",
      "F1-score: \t0.32973, \t[0.         0.51324308 0.80565693 0.        ]\n",
      "Recall: \t0.35505, \t[0.         0.66871166 0.75148936 0.        ]\n",
      "NMI: \t\t0.10676\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:09<00:00, 839.21it/s]\n",
      " 50%|█████     | 50/100 [00:54<00:54,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "GMM initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:49<00:49,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [04:06<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.77123, \t[0.88985626 0.77862017 0.75399395 0.66245555]\n",
      "F1-score: \t0.33313, \t[0.         0.50033715 0.83217391 0.        ]\n",
      "Recall: \t0.34587, \t[0.         0.5690184  0.81446809 0.        ]\n",
      "NMI: \t\t0.10442\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:07<00:00, 1020.29it/s]\n",
      " 50%|█████     | 50/100 [00:15<00:15,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "GMM initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:13<00:13,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.71272, \t[0.81028259 0.73395411 0.7169488  0.58971217]\n",
      "F1-score: \t0.31027, \t[0.         0.49704724 0.74401382 0.        ]\n",
      "Recall: \t0.35395, \t[0.         0.77453988 0.6412766  0.        ]\n",
      "NMI: \t\t0.10105\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:06<00:00, 1103.90it/s]\n",
      " 50%|█████     | 50/100 [00:13<00:13,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "GMM initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:51<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.78109, \t[0.88351846 0.79232156 0.7638979  0.6846291 ]\n",
      "F1-score: \t0.30421, \t[0.         0.49721707 0.71963331 0.        ]\n",
      "Recall: \t0.35584, \t[0.         0.82208589 0.6012766  0.        ]\n",
      "NMI: \t\t0.10720\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:06<00:00, 1106.56it/s]\n",
      " 50%|█████     | 50/100 [00:12<00:12,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "GMM initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:51<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.77779, \t[0.92788304 0.76809361 0.74467998 0.67049266]\n",
      "F1-score: \t0.32941, \t[0.         0.50728155 0.81037204 0.        ]\n",
      "Recall: \t0.35145, \t[0.         0.64110429 0.76468085 0.        ]\n",
      "NMI: \t\t0.10910\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:06<00:00, 1105.77it/s]\n",
      " 50%|█████     | 50/100 [00:12<00:12,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "GMM initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:51<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.77956, \t[0.92758902 0.77341656 0.76717612 0.65006338]\n",
      "F1-score: \t0.32964, \t[0.         0.51771429 0.80083083 0.        ]\n",
      "Recall: \t0.35827, \t[0.         0.69478528 0.73829787 0.        ]\n",
      "NMI: \t\t0.11422\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:06<00:00, 1111.46it/s]\n",
      " 50%|█████     | 50/100 [00:12<00:12,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "GMM initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:51<00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.77340, \t[0.8854296  0.7782953  0.75083331 0.67904015]\n",
      "F1-score: \t0.31077, \t[0.         0.49898854 0.6875308  0.05657238]\n",
      "Recall: \t0.36231, \t[0.         0.56748466 0.59361702 0.28813559]\n",
      "NMI: \t\t0.09783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = np.zeros((len(seeds), 4))\n",
    "for index, SEED in enumerate(seeds):\n",
    "    torch.random.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    dataset = CustomDataset(time_range=(0, 10))\n",
    "\n",
    "    # Stratified Sampling for train and val\n",
    "    train_idx, test_idx = train_test_split(np.arange(len(dataset)),\n",
    "                                                test_size=0.4,\n",
    "                                                random_state=SEED,\n",
    "                                                shuffle=True,\n",
    "                                                stratify=np.argmax(dataset.y,axis=-1))\n",
    "\n",
    "    # Subset dataset for train and val\n",
    "    train_val_dataset = dataset.get_subset(train_idx)\n",
    "    test_dataset = dataset.get_subset(test_idx)\n",
    "\n",
    "    train_idx,  val_idx = train_test_split(np.arange(len(train_val_dataset)),\n",
    "                                                test_size=0.4,\n",
    "                                                random_state=SEED,\n",
    "                                                shuffle=True,\n",
    "                                                stratify=np.argmax(train_val_dataset.y,axis=-1))\n",
    "\n",
    "    train_dataset = train_val_dataset.get_subset(train_idx)\n",
    "    val_dataset = train_val_dataset.get_subset(val_idx)\n",
    "\n",
    "    train_loader, val_loader, test_loader = load_data(train_dataset, val_dataset, test_dataset)\n",
    "\n",
    "    model = CAMELOT_GMM(input_shape=(train_dataset.x.shape[1], train_dataset.x.shape[2]), seed=SEED, num_clusters=10, latent_dim=64)\n",
    "    model = model.to(device)\n",
    "\n",
    "    train_x = torch.tensor(train_dataset.x).to(device)\n",
    "    train_y = torch.tensor(train_dataset.y).to(device)\n",
    "    val_x = torch.tensor(val_dataset.x).to(device)\n",
    "    val_y = torch.tensor(val_dataset.y).to(device)\n",
    "\n",
    "    model.initialize((train_x, train_y), (val_x, val_y))\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    cluster_optim = torch.optim.Adam([model.cluster_rep_set], lr=0.001)\n",
    "\n",
    "    lr_scheduler = MyLRScheduler(optimizer, patience=15, min_lr=0.00001, factor=0.25)\n",
    "    cluster_lr_scheduler = MyLRScheduler(cluster_optim, patience=15, min_lr=0.00001, factor=0.25)\n",
    "\n",
    "    loss_mat = np.zeros((100, 4, 2))\n",
    "\n",
    "    best_loss = 1e5\n",
    "    count = 0\n",
    "    for i in trange(100):\n",
    "        for step, (x_train, y_train) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            cluster_optim.zero_grad()\n",
    "            \n",
    "            y_pred, probs = model.forward_pass(x_train)\n",
    "            \n",
    "            loss_weights = class_weight(y_train)\n",
    "            \n",
    "            common_loss = calc_pred_loss(y_train, y_pred, loss_weights)\n",
    "            \n",
    "            enc_loss = common_loss + model.alpha * calc_dist_loss(probs) + \\\n",
    "            + calc_l1_l2_loss(part=model.Encoder) \n",
    "            enc_loss.backward(retain_graph=True, inputs=list(model.Encoder.parameters()))\n",
    "            \n",
    "            idnetifier_loss = common_loss + model.alpha * calc_dist_loss(probs) + \\\n",
    "            + calc_l1_l2_loss(layers=[model.Identifier.fc2])\n",
    "            idnetifier_loss.backward(retain_graph=True, inputs=list(model.Identifier.parameters()))\n",
    "            \n",
    "            pred_loss = common_loss + calc_l1_l2_loss(layers=[model.Predictor.fc2, model.Predictor.fc3])\n",
    "            pred_loss.backward(retain_graph=True, inputs=list(model.Predictor.parameters()))\n",
    "            \n",
    "            clus_loss = common_loss + model.beta * calc_clus_loss(model.cluster_rep_set)\n",
    "            clus_loss.backward(inputs=model.cluster_rep_set)\n",
    "\n",
    "            optimizer.step()\n",
    "            cluster_optim.step()\n",
    "\n",
    "            loss_mat[i, 0, 0] += enc_loss.item()\n",
    "            loss_mat[i, 1, 0] += idnetifier_loss.item()\n",
    "            loss_mat[i, 2, 0] += pred_loss.item()\n",
    "            loss_mat[i, 3, 0] += clus_loss.item()\n",
    "                            \n",
    "        with torch.no_grad():\n",
    "            for step, (x_val, y_val) in enumerate(val_loader):\n",
    "                y_pred, probs = model.forward_pass(x_val)\n",
    "                \n",
    "                loss_weights = class_weight(y_val)\n",
    "                \n",
    "                common_loss = calc_pred_loss(y_val, y_pred, loss_weights)\n",
    "            \n",
    "                enc_loss = common_loss + model.alpha * calc_dist_loss(probs) + \\\n",
    "                + calc_l1_l2_loss(part=model.Encoder) \n",
    "\n",
    "                idnetifier_loss = common_loss + model.alpha * calc_dist_loss(probs) + \\\n",
    "                + calc_l1_l2_loss(layers=[model.Identifier.fc2])\n",
    "\n",
    "                pred_loss = common_loss + calc_l1_l2_loss(layers=[model.Predictor.fc2, model.Predictor.fc3])\n",
    "\n",
    "                clus_loss = common_loss + model.beta * calc_clus_loss(model.cluster_rep_set)\n",
    "                \n",
    "                loss_mat[i, 0, 1] += enc_loss.item()\n",
    "                loss_mat[i, 1, 1] += idnetifier_loss.item()\n",
    "                loss_mat[i, 2, 1] += pred_loss.item()\n",
    "                loss_mat[i, 3, 1] += clus_loss.item()\n",
    "            \n",
    "            if i >= 30:\n",
    "                if loss_mat[i, 0, 1] < best_loss:\n",
    "                    count = 0\n",
    "                    best_loss = loss_mat[i, 0, 1]\n",
    "                    torch.save(model.state_dict(), './best_model')\n",
    "                else:\n",
    "                    count += 1\n",
    "                    if count >= 50:\n",
    "                        model.load_state_dict(torch.load('./best_model'))\n",
    "        lr_scheduler.step(loss_mat[i, 0, 1])\n",
    "        cluster_lr_scheduler.step(loss_mat[i, 0, 1])\n",
    "\n",
    "    model.load_state_dict(torch.load('./best_model'))\n",
    "\n",
    "    real, preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for _, (x, y) in enumerate(test_loader):\n",
    "            y_pred, _ = model.forward_pass(x)\n",
    "            preds.extend(list(y_pred.cpu().detach().numpy()))\n",
    "            real.extend(list(y.cpu().detach().numpy()))\n",
    "\n",
    "    auc = roc_auc_score(real, preds, average=None)\n",
    "\n",
    "    labels_true, labels_pred = np.argmax(real, axis=1), np.argmax(preds, axis=1)\n",
    "\n",
    "    # Compute F1\n",
    "    f1 = f1_score(labels_true, labels_pred, average=None)\n",
    "\n",
    "    # Compute Recall\n",
    "    rec = recall_score(labels_true, labels_pred, average=None)\n",
    "\n",
    "    # Compute NMI\n",
    "    nmi = normalized_mutual_info_score(labels_true, labels_pred)\n",
    "\n",
    "    print(f'AUCROC: \\t{auc.mean():.5f}, \\t{auc}')\n",
    "    print(f'F1-score: \\t{f1.mean():.5f}, \\t{f1}')\n",
    "    print(f'Recall: \\t{rec.mean():.5f}, \\t{rec}')\n",
    "    print(f'NMI: \\t\\t{nmi:.5f}')\n",
    "    \n",
    "    results[index, 0] = auc.mean()\n",
    "    results[index, 1] = f1.mean()\n",
    "    results[index, 2] = rec.mean()\n",
    "    results[index, 3] = nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.768 (0.019)\n",
      "F1 score: 0.324 (0.012)\n",
      "Recall: 0.353 (0.006)\n",
      "NMI: 0.107 (0.006)\n"
     ]
    }
   ],
   "source": [
    "for m, u, std in zip(metrics, results.mean(axis=0), results.std(axis=0)):\n",
    "    print(f'{m}: {u:.3f} ({std:.3f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:07<00:00, 1076.60it/s]\n",
      " 50%|█████     | 50/100 [00:13<00:13,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "Kmeans initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:50<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.76633, \t[0.88588697 0.77185946 0.75292808 0.65463438]\n",
      "F1-score: \t0.32905, \t[0.         0.50461538 0.8115747  0.        ]\n",
      "Recall: \t0.34966, \t[0.         0.62883436 0.76978723 0.        ]\n",
      "NMI: \t\t0.10370\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:06<00:00, 1100.72it/s]\n",
      " 50%|█████     | 50/100 [00:12<00:12,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "Kmeans initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:50<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.76308, \t[0.88012088 0.74462874 0.70888232 0.71867043]\n",
      "F1-score: \t0.32137, \t[0.         0.50482936 0.70271605 0.07792208]\n",
      "Recall: \t0.39067, \t[0.         0.60122699 0.60553191 0.3559322 ]\n",
      "NMI: \t\t0.09408\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:07<00:00, 1085.11it/s]\n",
      " 50%|█████     | 50/100 [00:12<00:12,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "Kmeans initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:10<00:10,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:49<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.72043, \t[0.78025155 0.71248393 0.68482289 0.70416942]\n",
      "F1-score: \t0.33558, \t[0.         0.50549451 0.83682732 0.        ]\n",
      "Recall: \t0.34706, \t[0.         0.56441718 0.82382979 0.        ]\n",
      "NMI: \t\t0.10594\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:06<00:00, 1107.13it/s]\n",
      " 50%|█████     | 50/100 [00:12<00:12,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "Kmeans initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:50<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.75705, \t[0.86030709 0.78133911 0.75903426 0.62750283]\n",
      "F1-score: \t0.31575, \t[0.         0.50331126 0.75970874 0.        ]\n",
      "Recall: \t0.35591, \t[0.         0.75766871 0.66595745 0.        ]\n",
      "NMI: \t\t0.10010\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:07<00:00, 1084.54it/s]\n",
      " 50%|█████     | 50/100 [00:12<00:12,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "Kmeans initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:10<00:10,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:49<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.75598, \t[0.89910977 0.73690952 0.7277859  0.66009714]\n",
      "F1-score: \t0.32616, \t[0.         0.50643275 0.72865182 0.06956522]\n",
      "Recall: \t0.37528, \t[0.         0.66411043 0.63361702 0.20338983]\n",
      "NMI: \t\t0.08907\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:06<00:00, 1106.86it/s]\n",
      " 50%|█████     | 50/100 [00:12<00:12,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "Kmeans initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.77352, \t[0.90526789 0.7793179  0.75719359 0.65228157]\n",
      "F1-score: \t0.32591, \t[0.         0.5002978  0.80336058 0.        ]\n",
      "Recall: \t0.34923, \t[0.         0.64417178 0.75276596 0.        ]\n",
      "NMI: \t\t0.10292\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:07<00:00, 1086.58it/s]\n",
      " 50%|█████     | 50/100 [00:12<00:12,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "Kmeans initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:49<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.78835, \t[0.90450016 0.7826086  0.75749047 0.70881614]\n",
      "F1-score: \t0.29946, \t[0.         0.48165569 0.71619914 0.        ]\n",
      "Recall: \t0.34706, \t[0.         0.78527607 0.60297872 0.        ]\n",
      "NMI: \t\t0.08944\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:07<00:00, 1083.94it/s]\n",
      " 50%|█████     | 50/100 [00:12<00:12,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "Kmeans initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:10<00:10,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:49<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.78076, \t[0.92784221 0.75823952 0.76469366 0.67225936]\n",
      "F1-score: \t0.33205, \t[0.09929078 0.45175936 0.77714286 0.        ]\n",
      "Recall: \t0.41372, \t[0.35       0.61042945 0.69446809 0.        ]\n",
      "NMI: \t\t0.12201\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:07<00:00, 1088.79it/s]\n",
      " 50%|█████     | 50/100 [00:12<00:12,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "Kmeans initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:50<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.78416, \t[0.92479582 0.79696257 0.7754283  0.6394351 ]\n",
      "F1-score: \t0.32020, \t[0.         0.51378958 0.7670303  0.        ]\n",
      "Recall: \t0.36117, \t[0.         0.77147239 0.67319149 0.        ]\n",
      "NMI: \t\t0.11311\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:07<00:00, 1080.58it/s]\n",
      " 50%|█████     | 50/100 [00:12<00:12,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "Kmeans initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:50<00:00,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.74896, \t[0.84658608 0.77079771 0.74461885 0.63384054]\n",
      "F1-score: \t0.32546, \t[0.         0.49759615 0.80425436 0.        ]\n",
      "Recall: \t0.34778, \t[0.         0.63496933 0.75617021 0.        ]\n",
      "NMI: \t\t0.09260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = np.zeros((len(seeds), 4))\n",
    "for index, SEED in enumerate(seeds):\n",
    "    torch.random.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    dataset = CustomDataset(time_range=(0, 10))\n",
    "\n",
    "    # Stratified Sampling for train and val\n",
    "    train_idx, test_idx = train_test_split(np.arange(len(dataset)),\n",
    "                                                test_size=0.4,\n",
    "                                                random_state=SEED,\n",
    "                                                shuffle=True,\n",
    "                                                stratify=np.argmax(dataset.y,axis=-1))\n",
    "\n",
    "    # Subset dataset for train and val\n",
    "    train_val_dataset = dataset.get_subset(train_idx)\n",
    "    test_dataset = dataset.get_subset(test_idx)\n",
    "\n",
    "    train_idx,  val_idx = train_test_split(np.arange(len(train_val_dataset)),\n",
    "                                                test_size=0.4,\n",
    "                                                random_state=SEED,\n",
    "                                                shuffle=True,\n",
    "                                                stratify=np.argmax(train_val_dataset.y,axis=-1))\n",
    "\n",
    "    train_dataset = train_val_dataset.get_subset(train_idx)\n",
    "    val_dataset = train_val_dataset.get_subset(val_idx)\n",
    "\n",
    "    train_loader, val_loader, test_loader = load_data(train_dataset, val_dataset, test_dataset)\n",
    "\n",
    "    model = Camelot_GRU(input_shape=(train_dataset.x.shape[1], train_dataset.x.shape[2]), seed=SEED, num_clusters=10, latent_dim=64)\n",
    "    model = model.to(device)\n",
    "\n",
    "    train_x = torch.tensor(train_dataset.x).to(device)\n",
    "    train_y = torch.tensor(train_dataset.y).to(device)\n",
    "    val_x = torch.tensor(val_dataset.x).to(device)\n",
    "    val_y = torch.tensor(val_dataset.y).to(device)\n",
    "\n",
    "    model.initialize((train_x, train_y), (val_x, val_y))\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    cluster_optim = torch.optim.Adam([model.cluster_rep_set], lr=0.001)\n",
    "\n",
    "    lr_scheduler = MyLRScheduler(optimizer, patience=15, min_lr=0.00001, factor=0.25)\n",
    "    cluster_lr_scheduler = MyLRScheduler(cluster_optim, patience=15, min_lr=0.00001, factor=0.25)\n",
    "\n",
    "    loss_mat = np.zeros((100, 4, 2))\n",
    "\n",
    "    best_loss = 1e5\n",
    "    count = 0\n",
    "    for i in trange(100):\n",
    "        for step, (x_train, y_train) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            cluster_optim.zero_grad()\n",
    "            \n",
    "            y_pred, probs = model.forward_pass(x_train)\n",
    "            \n",
    "            loss_weights = class_weight(y_train)\n",
    "            \n",
    "            common_loss = calc_pred_loss(y_train, y_pred, loss_weights)\n",
    "            \n",
    "            enc_loss = common_loss + model.alpha * calc_dist_loss(probs) + \\\n",
    "            + calc_l1_l2_loss(part=model.Encoder) \n",
    "            enc_loss.backward(retain_graph=True, inputs=list(model.Encoder.parameters()))\n",
    "            \n",
    "            idnetifier_loss = common_loss + model.alpha * calc_dist_loss(probs) + \\\n",
    "            + calc_l1_l2_loss(layers=[model.Identifier.fc2])\n",
    "            idnetifier_loss.backward(retain_graph=True, inputs=list(model.Identifier.parameters()))\n",
    "            \n",
    "            pred_loss = common_loss + calc_l1_l2_loss(layers=[model.Predictor.fc2, model.Predictor.fc3])\n",
    "            pred_loss.backward(retain_graph=True, inputs=list(model.Predictor.parameters()))\n",
    "            \n",
    "            clus_loss = common_loss + model.beta * calc_clus_loss(model.cluster_rep_set)\n",
    "            clus_loss.backward(inputs=model.cluster_rep_set)\n",
    "\n",
    "            optimizer.step()\n",
    "            cluster_optim.step()\n",
    "\n",
    "            loss_mat[i, 0, 0] += enc_loss.item()\n",
    "            loss_mat[i, 1, 0] += idnetifier_loss.item()\n",
    "            loss_mat[i, 2, 0] += pred_loss.item()\n",
    "            loss_mat[i, 3, 0] += clus_loss.item()\n",
    "                            \n",
    "        with torch.no_grad():\n",
    "            for step, (x_val, y_val) in enumerate(val_loader):\n",
    "                y_pred, probs = model.forward_pass(x_val)\n",
    "                \n",
    "                loss_weights = class_weight(y_val)\n",
    "                \n",
    "                common_loss = calc_pred_loss(y_val, y_pred, loss_weights)\n",
    "            \n",
    "                enc_loss = common_loss + model.alpha * calc_dist_loss(probs) + \\\n",
    "                + calc_l1_l2_loss(part=model.Encoder) \n",
    "\n",
    "                idnetifier_loss = common_loss + model.alpha * calc_dist_loss(probs) + \\\n",
    "                + calc_l1_l2_loss(layers=[model.Identifier.fc2])\n",
    "\n",
    "                pred_loss = common_loss + calc_l1_l2_loss(layers=[model.Predictor.fc2, model.Predictor.fc3])\n",
    "\n",
    "                clus_loss = common_loss + model.beta * calc_clus_loss(model.cluster_rep_set)\n",
    "                \n",
    "                loss_mat[i, 0, 1] += enc_loss.item()\n",
    "                loss_mat[i, 1, 1] += idnetifier_loss.item()\n",
    "                loss_mat[i, 2, 1] += pred_loss.item()\n",
    "                loss_mat[i, 3, 1] += clus_loss.item()\n",
    "            \n",
    "            if i >= 30:\n",
    "                if loss_mat[i, 0, 1] < best_loss:\n",
    "                    count = 0\n",
    "                    best_loss = loss_mat[i, 0, 1]\n",
    "                    torch.save(model.state_dict(), './best_model')\n",
    "                else:\n",
    "                    count += 1\n",
    "                    if count >= 50:\n",
    "                        model.load_state_dict(torch.load('./best_model'))\n",
    "        lr_scheduler.step(loss_mat[i, 0, 1])\n",
    "        cluster_lr_scheduler.step(loss_mat[i, 0, 1])\n",
    "\n",
    "    model.load_state_dict(torch.load('./best_model'))\n",
    "\n",
    "    real, preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for _, (x, y) in enumerate(test_loader):\n",
    "            y_pred, _ = model.forward_pass(x)\n",
    "            preds.extend(list(y_pred.cpu().detach().numpy()))\n",
    "            real.extend(list(y.cpu().detach().numpy()))\n",
    "\n",
    "    auc = roc_auc_score(real, preds, average=None)\n",
    "\n",
    "    labels_true, labels_pred = np.argmax(real, axis=1), np.argmax(preds, axis=1)\n",
    "\n",
    "    # Compute F1\n",
    "    f1 = f1_score(labels_true, labels_pred, average=None)\n",
    "\n",
    "    # Compute Recall\n",
    "    rec = recall_score(labels_true, labels_pred, average=None)\n",
    "\n",
    "    # Compute NMI\n",
    "    nmi = normalized_mutual_info_score(labels_true, labels_pred)\n",
    "\n",
    "    print(f'AUCROC: \\t{auc.mean():.5f}, \\t{auc}')\n",
    "    print(f'F1-score: \\t{f1.mean():.5f}, \\t{f1}')\n",
    "    print(f'Recall: \\t{rec.mean():.5f}, \\t{rec}')\n",
    "    print(f'NMI: \\t\\t{nmi:.5f}')\n",
    "    \n",
    "    results[index, 0] = auc.mean()\n",
    "    results[index, 1] = f1.mean()\n",
    "    results[index, 2] = rec.mean()\n",
    "    results[index, 3] = nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.764 (0.019)\n",
      "F1 score: 0.323 (0.010)\n",
      "Recall: 0.364 (0.022)\n",
      "NMI: 0.101 (0.010)\n"
     ]
    }
   ],
   "source": [
    "for m, u, std in zip(metrics, results.mean(axis=0), results.std(axis=0)):\n",
    "    print(f'{m}: {u:.3f} ({std:.3f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:07<00:00, 1023.75it/s]\n",
      " 50%|█████     | 50/100 [00:14<00:14,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "Kmeans initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:12<00:12,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:01<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.76494, \t[0.9008984  0.75622021 0.77199639 0.63063523]\n",
      "F1-score: \t0.31936, \t[0.         0.51303015 0.76442075 0.        ]\n",
      "Recall: \t0.36025, \t[0.         0.76993865 0.67106383 0.        ]\n",
      "NMI: \t\t0.11115\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:07<00:00, 978.71it/s] \n",
      " 50%|█████     | 50/100 [00:15<00:15,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "Kmeans initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:54<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.75550, \t[0.85320157 0.73391938 0.73845301 0.69644359]\n",
      "F1-score: \t0.28916, \t[0.         0.47324193 0.68341183 0.        ]\n",
      "Recall: \t0.34407, \t[0.         0.82055215 0.55574468 0.        ]\n",
      "NMI: \t\t0.08705\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:06<00:00, 1100.36it/s]\n",
      " 50%|█████     | 50/100 [00:12<00:12,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "Kmeans initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:52<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.77313, \t[0.89078732 0.73689279 0.75440522 0.71044543]\n",
      "F1-score: \t0.33815, \t[0.12972973 0.44101956 0.78184826 0.        ]\n",
      "Recall: \t0.46860, \t[0.6        0.57055215 0.70382979 0.        ]\n",
      "NMI: \t\t0.11617\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:07<00:00, 1078.95it/s]\n",
      " 50%|█████     | 50/100 [00:13<00:13,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "Kmeans initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:52<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.76211, \t[0.89385005 0.74876556 0.75739878 0.64841165]\n",
      "F1-score: \t0.30739, \t[0.         0.49763033 0.7319406  0.        ]\n",
      "Recall: \t0.35598, \t[0.         0.80521472 0.6187234  0.        ]\n",
      "NMI: \t\t0.10082\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:06<00:00, 1103.46it/s]\n",
      " 50%|█████     | 50/100 [00:12<00:12,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "Kmeans initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:54<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.76504, \t[0.89524665 0.75798443 0.73264982 0.67427565]\n",
      "F1-score: \t0.32580, \t[0.         0.48758752 0.81560284 0.        ]\n",
      "Recall: \t0.34260, \t[0.         0.58742331 0.78297872 0.        ]\n",
      "NMI: \t\t0.09139\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:07<00:00, 1079.96it/s]\n",
      " 50%|█████     | 50/100 [00:13<00:13,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "Kmeans initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.75280, \t[0.88160732 0.76639854 0.74733941 0.61587343]\n",
      "F1-score: \t0.31935, \t[0.         0.49781659 0.77958127 0.        ]\n",
      "Recall: \t0.35112, \t[0.         0.6993865  0.70510638 0.        ]\n",
      "NMI: \t\t0.09828\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:06<00:00, 1100.15it/s]\n",
      " 50%|█████     | 50/100 [00:12<00:12,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "Kmeans initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:52<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.74928, \t[0.87807906 0.74374095 0.72225864 0.65302191]\n",
      "F1-score: \t0.33245, \t[0.         0.48218347 0.84760705 0.        ]\n",
      "Recall: \t0.33672, \t[0.         0.48773006 0.85914894 0.        ]\n",
      "NMI: \t\t0.10524\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:07<00:00, 1087.18it/s]\n",
      " 50%|█████     | 50/100 [00:12<00:12,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "Kmeans initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:53<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.76488, \t[0.92445279 0.7316153  0.756213   0.64723665]\n",
      "F1-score: \t0.31285, \t[0.         0.49824209 0.75317693 0.        ]\n",
      "Recall: \t0.35412, \t[0.         0.7607362  0.65574468 0.        ]\n",
      "NMI: \t\t0.10024\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:06<00:00, 1100.24it/s]\n",
      " 50%|█████     | 50/100 [00:12<00:12,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "Kmeans initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:52<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.78280, \t[0.93373081 0.78482871 0.77156271 0.64107561]\n",
      "F1-score: \t0.33098, \t[0.         0.52765487 0.79625731 0.        ]\n",
      "Recall: \t0.36396, \t[0.         0.73159509 0.72425532 0.        ]\n",
      "NMI: \t\t0.12287\n",
      "\n",
      "MIMIC data has been subsettted to the following features: \n",
      " ['DBP', 'ESI', 'HR', 'RR', 'SBP', 'SPO2', 'TEMP', 'age', 'gender'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7701/7701 [00:06<00:00, 1103.17it/s]\n",
      " 50%|█████     | 50/100 [00:12<00:12,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder initialization done!\n",
      "Kmeans initialization done!\n",
      "Cluster initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:11<00:11,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:52<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC: \t0.76780, \t[0.90457367 0.77043117 0.74609745 0.65009142]\n",
      "F1-score: \t0.32388, \t[0.         0.49182314 0.80370036 0.        ]\n",
      "Recall: \t0.34514, \t[0.         0.62269939 0.75787234 0.        ]\n",
      "NMI: \t\t0.09293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = np.zeros((len(seeds), 4))\n",
    "for index, SEED in enumerate(seeds):\n",
    "    torch.random.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    dataset = CustomDataset(time_range=(0, 10))\n",
    "\n",
    "    # Stratified Sampling for train and val\n",
    "    train_idx, test_idx = train_test_split(np.arange(len(dataset)),\n",
    "                                                test_size=0.4,\n",
    "                                                random_state=SEED,\n",
    "                                                shuffle=True,\n",
    "                                                stratify=np.argmax(dataset.y,axis=-1))\n",
    "\n",
    "    # Subset dataset for train and val\n",
    "    train_val_dataset = dataset.get_subset(train_idx)\n",
    "    test_dataset = dataset.get_subset(test_idx)\n",
    "\n",
    "    train_idx,  val_idx = train_test_split(np.arange(len(train_val_dataset)),\n",
    "                                                test_size=0.4,\n",
    "                                                random_state=SEED,\n",
    "                                                shuffle=True,\n",
    "                                                stratify=np.argmax(train_val_dataset.y,axis=-1))\n",
    "\n",
    "    train_dataset = train_val_dataset.get_subset(train_idx)\n",
    "    val_dataset = train_val_dataset.get_subset(val_idx)\n",
    "\n",
    "    train_loader, val_loader, test_loader = load_data(train_dataset, val_dataset, test_dataset)\n",
    "\n",
    "    model = Camelot_denoising(input_shape=(train_dataset.x.shape[1], train_dataset.x.shape[2]), seed=SEED, num_clusters=10, latent_dim=64)\n",
    "    model = model.to(device)\n",
    "\n",
    "    train_x = torch.tensor(train_dataset.x).to(device)\n",
    "    train_y = torch.tensor(train_dataset.y).to(device)\n",
    "    val_x = torch.tensor(val_dataset.x).to(device)\n",
    "    val_y = torch.tensor(val_dataset.y).to(device)\n",
    "\n",
    "    model.initialize((train_x, train_y), (val_x, val_y))\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    cluster_optim = torch.optim.Adam([model.cluster_rep_set], lr=0.001)\n",
    "\n",
    "    lr_scheduler = MyLRScheduler(optimizer, patience=15, min_lr=0.00001, factor=0.25)\n",
    "    cluster_lr_scheduler = MyLRScheduler(cluster_optim, patience=15, min_lr=0.00001, factor=0.25)\n",
    "\n",
    "    loss_mat = np.zeros((100, 4, 2))\n",
    "\n",
    "    best_loss = 1e5\n",
    "    count = 0\n",
    "    for i in trange(100):\n",
    "        for step, (x_train, y_train) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            cluster_optim.zero_grad()\n",
    "            \n",
    "            y_pred, probs = model.forward_pass(x_train)\n",
    "            \n",
    "            loss_weights = class_weight(y_train)\n",
    "            \n",
    "            common_loss = calc_pred_loss(y_train, y_pred, loss_weights)\n",
    "            \n",
    "            enc_loss = common_loss + model.alpha * calc_dist_loss(probs) + \\\n",
    "            + calc_l1_l2_loss(part=model.Encoder) \n",
    "            enc_loss.backward(retain_graph=True, inputs=list(model.Encoder.parameters()))\n",
    "            \n",
    "            idnetifier_loss = common_loss + model.alpha * calc_dist_loss(probs) + \\\n",
    "            + calc_l1_l2_loss(layers=[model.Identifier.fc2])\n",
    "            idnetifier_loss.backward(retain_graph=True, inputs=list(model.Identifier.parameters()))\n",
    "            \n",
    "            pred_loss = common_loss + calc_l1_l2_loss(layers=[model.Predictor.fc2, model.Predictor.fc3])\n",
    "            pred_loss.backward(retain_graph=True, inputs=list(model.Predictor.parameters()))\n",
    "            \n",
    "            clus_loss = common_loss + model.beta * calc_clus_loss(model.cluster_rep_set)\n",
    "            clus_loss.backward(inputs=model.cluster_rep_set)\n",
    "\n",
    "            optimizer.step()\n",
    "            cluster_optim.step()\n",
    "\n",
    "            loss_mat[i, 0, 0] += enc_loss.item()\n",
    "            loss_mat[i, 1, 0] += idnetifier_loss.item()\n",
    "            loss_mat[i, 2, 0] += pred_loss.item()\n",
    "            loss_mat[i, 3, 0] += clus_loss.item()\n",
    "                            \n",
    "        with torch.no_grad():\n",
    "            for step, (x_val, y_val) in enumerate(val_loader):\n",
    "                y_pred, probs = model.forward_pass(x_val)\n",
    "                \n",
    "                loss_weights = class_weight(y_val)\n",
    "                \n",
    "                common_loss = calc_pred_loss(y_val, y_pred, loss_weights)\n",
    "            \n",
    "                enc_loss = common_loss + model.alpha * calc_dist_loss(probs) + \\\n",
    "                + calc_l1_l2_loss(part=model.Encoder) \n",
    "\n",
    "                idnetifier_loss = common_loss + model.alpha * calc_dist_loss(probs) + \\\n",
    "                + calc_l1_l2_loss(layers=[model.Identifier.fc2])\n",
    "\n",
    "                pred_loss = common_loss + calc_l1_l2_loss(layers=[model.Predictor.fc2, model.Predictor.fc3])\n",
    "\n",
    "                clus_loss = common_loss + model.beta * calc_clus_loss(model.cluster_rep_set)\n",
    "                \n",
    "                loss_mat[i, 0, 1] += enc_loss.item()\n",
    "                loss_mat[i, 1, 1] += idnetifier_loss.item()\n",
    "                loss_mat[i, 2, 1] += pred_loss.item()\n",
    "                loss_mat[i, 3, 1] += clus_loss.item()\n",
    "            \n",
    "            if i >= 30:\n",
    "                if loss_mat[i, 0, 1] < best_loss:\n",
    "                    count = 0\n",
    "                    best_loss = loss_mat[i, 0, 1]\n",
    "                    torch.save(model.state_dict(), './best_model')\n",
    "                else:\n",
    "                    count += 1\n",
    "                    if count >= 50:\n",
    "                        model.load_state_dict(torch.load('./best_model'))\n",
    "        lr_scheduler.step(loss_mat[i, 0, 1])\n",
    "        cluster_lr_scheduler.step(loss_mat[i, 0, 1])\n",
    "\n",
    "    model.load_state_dict(torch.load('./best_model'))\n",
    "\n",
    "    real, preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for _, (x, y) in enumerate(test_loader):\n",
    "            y_pred, _ = model.forward_pass(x)\n",
    "            preds.extend(list(y_pred.cpu().detach().numpy()))\n",
    "            real.extend(list(y.cpu().detach().numpy()))\n",
    "\n",
    "    auc = roc_auc_score(real, preds, average=None)\n",
    "\n",
    "    labels_true, labels_pred = np.argmax(real, axis=1), np.argmax(preds, axis=1)\n",
    "\n",
    "    # Compute F1\n",
    "    f1 = f1_score(labels_true, labels_pred, average=None)\n",
    "\n",
    "    # Compute Recall\n",
    "    rec = recall_score(labels_true, labels_pred, average=None)\n",
    "\n",
    "    # Compute NMI\n",
    "    nmi = normalized_mutual_info_score(labels_true, labels_pred)\n",
    "\n",
    "    print(f'AUCROC: \\t{auc.mean():.5f}, \\t{auc}')\n",
    "    print(f'F1-score: \\t{f1.mean():.5f}, \\t{f1}')\n",
    "    print(f'Recall: \\t{rec.mean():.5f}, \\t{rec}')\n",
    "    print(f'NMI: \\t\\t{nmi:.5f}')\n",
    "    \n",
    "    results[index, 0] = auc.mean()\n",
    "    results[index, 1] = f1.mean()\n",
    "    results[index, 2] = rec.mean()\n",
    "    results[index, 3] = nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.764 (0.009)\n",
      "F1 score: 0.320 (0.013)\n",
      "Recall: 0.362 (0.036)\n",
      "NMI: 0.103 (0.011)\n"
     ]
    }
   ],
   "source": [
    "for m, u, std in zip(metrics, results.mean(axis=0), results.std(axis=0)):\n",
    "    print(f'{m}: {u:.3f} ({std:.3f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
